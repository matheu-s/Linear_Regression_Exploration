# Exploring Linear Regression: A Comparison of Scikit-learn and Custom Gradient Descent

## Introduction

In this notebook, we will explore **linear regression**, a fundamental algorithm in machine learning used to model the relationship between a dependent variable and one or more independent variables.

Specifically, we will:

- Utilize **Scikit-learn’s LinearRegression** implementation to quickly create and train a linear model.
- Code our own version of **gradient descent** from scratch to understand the underlying mathematics and mechanics of linear regression.

We will apply both methods to a **univariate linear regression problem**, where:

- **X** represents the **years of experience** of employees.
- **Y** represents the corresponding **salary amounts**.

### Objective

The primary goal is to compare the results of Scikit-learn’s built-in linear regression with our manually coded gradient descent. By doing this, we can gain a better understanding of how the algorithms work from scratch.

### What you'll learn:

- How to implement and use **Scikit-learn's LinearRegression** to fit a simple linear model.
- How to **code gradient descent from scratch**, step by step, to solve the same problem.
- **Compare** the results of both approaches and evaluate their performance.

Let's dive into the world of **linear regression** and discover how the two approaches fare when applied to the years of experience vs. salary dataset!
